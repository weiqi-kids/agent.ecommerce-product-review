#!/bin/bash
# Reddit Layer - è³‡æ–™æŠ“å–è…³æœ¬
#
# ä½¿ç”¨æ–¹å¼ï¼š
#   ./fetch.sh --query "AirPods"              # ç”ŸæˆæŠ“å–è¨ˆåŠƒ
#   ./fetch.sh --query "AirPods" --use-api    # ä½¿ç”¨ Reddit APIï¼ˆéœ€è¨­å®šç’°å¢ƒè®Šæ•¸ï¼‰
#
# æ¨¡å¼ï¼š
#   1. API æ¨¡å¼ï¼šè¨­å®š REDDIT_CLIENT_ID/SECRET å¾Œè‡ªå‹•å•Ÿç”¨
#   2. MCP æ¨¡å¼ï¼šè¼¸å‡ºæŠ“å–è¨ˆåŠƒï¼Œç”± Claude ä½¿ç”¨ MCP fetch_url åŸ·è¡Œ

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../../../.." && pwd)"

source "$PROJECT_ROOT/lib/args.sh"
source "$PROJECT_ROOT/lib/core.sh"

LAYER_NAME="reddit"
RAW_DIR="$PROJECT_ROOT/docs/Extractor/$LAYER_NAME/raw"
PLAN_DIR="$PROJECT_ROOT/docs/Extractor/$LAYER_NAME/fetch_plans"
QUERIES_FILE="$SCRIPT_DIR/product_queries.txt"

# é è¨­å€¼
MAX_POSTS=50
USE_API=false

# è§£æåƒæ•¸
QUERY=""
OUTPUT_PLAN=false

while [[ $# -gt 0 ]]; do
  case "$1" in
    --query)
      QUERY="$2"
      shift 2
      ;;
    --use-api)
      USE_API=true
      shift
      ;;
    --output-plan)
      OUTPUT_PLAN=true
      shift
      ;;
    --max-posts)
      MAX_POSTS="$2"
      shift 2
      ;;
    *)
      echo "æœªçŸ¥åƒæ•¸: $1" >&2
      exit 1
      ;;
  esac
done

# ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
mkdir -p "$RAW_DIR" "$PLAN_DIR"

echo "ğŸ” Reddit Layer: é–‹å§‹è™•ç†"

# æª¢æŸ¥ Reddit API æ†‘è­‰
if [[ -n "${REDDIT_CLIENT_ID:-}" ]] && [[ -n "${REDDIT_CLIENT_SECRET:-}" ]]; then
  echo "  âœ… Reddit API æ†‘è­‰å·²è¨­å®š"
  HAS_API=true
else
  echo "  âš ï¸  Reddit API æœªè¨­å®šï¼Œå°‡ä½¿ç”¨ MCP fetcher æ¨¡å¼"
  HAS_API=false
fi

# ç”Ÿæˆæœå°‹æŸ¥è©¢
generate_search_queries() {
  local query="$1"
  cat << EOF
site:reddit.com "${query}" review
site:reddit.com "${query}" worth it
site:reddit.com "${query}" problems
site:reddit.com "${query}" recommendation
site:reddit.com "${query}" after 1 year
EOF
}

# ç”ŸæˆæŠ“å–è¨ˆåŠƒ JSON
generate_fetch_plan() {
  local query="$1"
  local output_file="$2"

  # æ ¹æ“šç”¢å“é¡åˆ¥é¸æ“‡ subreddits
  local subreddits='["SkincareAddiction", "MakeupAddiction", "headphones", "gadgets", "BuyItForLife"]'

  cat > "$output_file" << EOF
{
  "layer": "reddit",
  "query": "${query}",
  "generated_at": "$(date -u '+%Y-%m-%dT%H:%M:%SZ')",
  "mode": "mcp_fetch",
  "search_queries": [
    "site:reddit.com \"${query}\" review",
    "site:reddit.com \"${query}\" worth it",
    "site:reddit.com \"${query}\" problems"
  ],
  "target_subreddits": ${subreddits},
  "max_posts": ${MAX_POSTS},
  "instructions": {
    "step1": "ä½¿ç”¨ WebSearch åŸ·è¡Œ search_queries ä¸­çš„æŸ¥è©¢",
    "step2": "å¾æœå°‹çµæœä¸­æå– Reddit URL",
    "step3": "ä½¿ç”¨ MCP fetch_url æŠ“å–æ¯å€‹ Reddit è¨è«–ä¸²",
    "step4": "AI èƒå–ç”¢å“ç›¸é—œè¨è«–ï¼Œè¼¸å‡º JSONL"
  }
}
EOF
  echo "  ğŸ“ æŠ“å–è¨ˆåŠƒå·²ç”Ÿæˆï¼š$output_file"
}

# å–®ä¸€æŸ¥è©¢æ¨¡å¼
if [[ -n "$QUERY" ]]; then
  echo "  ğŸ“ æŸ¥è©¢: $QUERY"

  if [[ "$HAS_API" == "true" ]] && [[ "$USE_API" == "true" ]]; then
    # ä½¿ç”¨ Reddit API
    echo "  ğŸ“¡ ä½¿ç”¨ Reddit API æ¨¡å¼"
    cd "$PROJECT_ROOT/scrapers"
    npx tsx src/reddit/scraper.ts \
      --query "$QUERY" \
      --output "$RAW_DIR" \
      --max-posts "$MAX_POSTS" \
      --use-api || {
      echo "  âš ï¸ API æŠ“å–å¤±æ•—ï¼Œåˆ‡æ›åˆ° MCP æ¨¡å¼"
      generate_fetch_plan "$QUERY" "$PLAN_DIR/reddit-$(echo "$QUERY" | tr ' ' '-' | tr '[:upper:]' '[:lower:]')-$(date +%Y-%m-%d).json"
    }
  else
    # è¼¸å‡º MCP æŠ“å–è¨ˆåŠƒ
    echo "  ğŸ“‹ ç”Ÿæˆ MCP æŠ“å–è¨ˆåŠƒ"
    generate_fetch_plan "$QUERY" "$PLAN_DIR/reddit-$(echo "$QUERY" | tr ' ' '-' | tr '[:upper:]' '[:lower:]')-$(date +%Y-%m-%d).json"
  fi

  echo "âœ… Reddit è™•ç†å®Œæˆ"
  exit 0
fi

# æ‰¹æ¬¡æ¨¡å¼ï¼šå¾ product_queries.txt è®€å–
if [[ ! -f "$QUERIES_FILE" ]]; then
  echo "âŒ æ‰¾ä¸åˆ° $QUERIES_FILE" >&2
  exit 1
fi

QUERY_COUNT=$(grep -cvE '^\s*(#|$)' "$QUERIES_FILE" 2>/dev/null || echo "0")
echo "  ğŸ“‹ å…± $QUERY_COUNT å€‹ç”¢å“æŸ¥è©¢"

CURRENT=0
while IFS= read -r line || [[ -n "$line" ]]; do
  [[ -z "$line" || "$line" == \#* ]] && continue

  CURRENT=$((CURRENT + 1))
  echo "  [$CURRENT/$QUERY_COUNT] $line"

  # ç”ŸæˆæŠ“å–è¨ˆåŠƒ
  SAFE_NAME=$(echo "$line" | tr ' ' '-' | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9-]//g')
  generate_fetch_plan "$line" "$PLAN_DIR/reddit-${SAFE_NAME}-$(date +%Y-%m-%d).json"

done < "$QUERIES_FILE"

echo ""
echo "ğŸ“Š å·²ç”Ÿæˆ $CURRENT å€‹æŠ“å–è¨ˆåŠƒ"
echo "ğŸ“ è¨ˆåŠƒä½ç½®ï¼š$PLAN_DIR"
echo ""
echo "ä¸‹ä¸€æ­¥ï¼šClaude å°‡è®€å–é€™äº›è¨ˆåŠƒä¸¦ä½¿ç”¨ MCP fetch_url åŸ·è¡ŒæŠ“å–"
echo "âœ… Reddit fetch å®Œæˆ"
