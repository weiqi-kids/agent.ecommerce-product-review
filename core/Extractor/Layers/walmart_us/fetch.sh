#!/bin/bash
#
# Walmart US è©•è«–æŠ“å–è…³æœ¬
#
# ç”¨æ³•ï¼š
#   ./fetch.sh                    # å¾ product_urls.txt æŠ“å–
#   ./fetch.sh --upc 012345678901 # é€é UPC æœå°‹ä¸¦æŠ“å–
#   ./fetch.sh --search "Sony"    # é€éåç¨±æœå°‹
#

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../../../.." && pwd)"
SCRAPER_DIR="$PROJECT_ROOT/scrapers"
OUTPUT_DIR="$PROJECT_ROOT/docs/Extractor/walmart_us/raw"

# é è¨­åƒæ•¸
MAX_REVIEWS=100
BATCH_SIZE=50
HEADLESS=true

# ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
mkdir -p "$OUTPUT_DIR"

cd "$SCRAPER_DIR"

# è™•ç†å‘½ä»¤åˆ—åƒæ•¸
if [[ "$1" == "--upc" ]]; then
    # UPC æœå°‹æ¨¡å¼
    UPC="$2"
    echo "ğŸ” é€é UPC æœå°‹: $UPC"
    npx tsx src/walmart/scraper.ts \
        --upc "$UPC" \
        --output "$OUTPUT_DIR" \
        --max-reviews "$MAX_REVIEWS" \
        --batch-size "$BATCH_SIZE" \
        --headless "$HEADLESS"

elif [[ "$1" == "--search" ]]; then
    # åç¨±æœå°‹æ¨¡å¼
    QUERY="$2"
    echo "ğŸ” é€éåç¨±æœå°‹: $QUERY"
    npx tsx src/walmart/scraper.ts \
        --search "$QUERY" \
        --output "$OUTPUT_DIR" \
        --max-reviews "$MAX_REVIEWS" \
        --batch-size "$BATCH_SIZE" \
        --headless "$HEADLESS"

elif [[ "$1" == "--url" ]]; then
    # å–®ä¸€ URL æ¨¡å¼
    URL="$2"
    echo "ğŸ“¦ æŠ“å–å–®ä¸€ç”¢å“: $URL"
    npx tsx src/walmart/scraper.ts \
        --url "$URL" \
        --output "$OUTPUT_DIR" \
        --max-reviews "$MAX_REVIEWS" \
        --batch-size "$BATCH_SIZE" \
        --headless "$HEADLESS"

else
    # å¾ product_urls.txt æ‰¹æ¬¡æŠ“å–
    URL_FILE="$SCRIPT_DIR/product_urls.txt"

    if [[ ! -f "$URL_FILE" ]]; then
        echo "âš ï¸ product_urls.txt ä¸å­˜åœ¨ï¼Œå»ºç«‹ç©ºæª”æ¡ˆ"
        touch "$URL_FILE"
        exit 0
    fi

    # è¨ˆç®— URL æ•¸é‡
    URL_COUNT=$(grep -c '^https' "$URL_FILE" 2>/dev/null || echo 0)
    echo "ğŸ“¦ æº–å‚™æŠ“å– $URL_COUNT å€‹ç”¢å“"

    # é€è¡Œè™•ç†
    while IFS= read -r url || [[ -n "$url" ]]; do
        # è·³éç©ºè¡Œå’Œè¨»è§£
        [[ -z "$url" || "$url" =~ ^# ]] && continue

        echo ""
        echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        echo "ğŸ›’ $url"

        npx tsx src/walmart/scraper.ts \
            --url "$url" \
            --output "$OUTPUT_DIR" \
            --max-reviews "$MAX_REVIEWS" \
            --batch-size "$BATCH_SIZE" \
            --headless "$HEADLESS" \
            || echo "âš ï¸ æŠ“å–å¤±æ•—ï¼Œç¹¼çºŒä¸‹ä¸€å€‹..."

        # éš¨æ©Ÿå»¶é²é¿å…è¢«å°é–
        sleep $((RANDOM % 5 + 3))

    done < "$URL_FILE"
fi

echo ""
echo "âœ… Walmart æŠ“å–å®Œæˆ"
echo "ğŸ“ è¼¸å‡ºç›®éŒ„: $OUTPUT_DIR"
ls -la "$OUTPUT_DIR"/*.jsonl 2>/dev/null | tail -5 || echo "ï¼ˆç„¡ JSONL æª”æ¡ˆï¼‰"
