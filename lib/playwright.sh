#!/usr/bin/env bash
# playwright.sh - Playwright çˆ¬èŸ² shell wrapper
# æ³¨æ„ï¼šé æœŸè¢«å…¶ä»– script ç”¨ `source` è¼‰å…¥
# ä¸åœ¨é€™è£¡ set -euo pipefailï¼Œäº¤çµ¦å‘¼å«ç«¯æ±ºå®šã€‚

if [[ -n "${PLAYWRIGHT_SH_LOADED:-}" ]]; then
  return 0 2>/dev/null || exit 0
fi
PLAYWRIGHT_SH_LOADED=1

_playwright_lib_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
. "${_playwright_lib_dir}/core.sh"

########################################
# playwright_check_env
#
# åŠŸèƒ½ï¼š
#   - æª¢æŸ¥ Playwright ç’°å¢ƒæ˜¯å¦å°±ç·’
#
# å›å‚³å€¼ï¼š
#   0  = ç’°å¢ƒå°±ç·’
#   >0 = ç¼ºå°‘ä¾è³´
########################################
playwright_check_env() {
  local err=0
  local project_root
  project_root="$(cd "${_playwright_lib_dir}/.." && pwd)"
  local scrapers_dir="$project_root/scrapers"

  # æª¢æŸ¥ Node.js
  if ! command -v node >/dev/null 2>&1; then
    echo "âŒ [playwright_check_env] ç¼ºå°‘ Node.js" >&2
    err=1
  fi

  # æª¢æŸ¥ npx (ç”¨æ–¼åŸ·è¡Œ tsx)
  if ! command -v npx >/dev/null 2>&1; then
    echo "âŒ [playwright_check_env] ç¼ºå°‘ npx" >&2
    err=1
  fi

  # æª¢æŸ¥ scrapers ç›®éŒ„
  if [[ ! -d "$scrapers_dir" ]]; then
    echo "âŒ [playwright_check_env] æ‰¾ä¸åˆ° scrapers/ ç›®éŒ„" >&2
    err=1
  fi

  # æª¢æŸ¥ node_modules
  if [[ ! -d "$scrapers_dir/node_modules" ]]; then
    echo "âš ï¸  [playwright_check_env] å°šæœªå®‰è£ä¾è³´ï¼Œå˜—è©¦å®‰è£..." >&2
    (cd "$scrapers_dir" && npm install) || {
      echo "âŒ [playwright_check_env] npm install å¤±æ•—" >&2
      err=1
    }
  fi

  return "$err"
}

########################################
# playwright_scrape SCRAPER_NAME SOURCE_URL OUTPUT_DIR [OPTIONS...]
#
# åŠŸèƒ½ï¼š
#   - åŸ·è¡ŒæŒ‡å®šå¹³å°çš„ Playwright çˆ¬èŸ²ï¼ŒæŠ“å–å–®ä¸€å•†å“é é¢
#
# åƒæ•¸ï¼š
#   SCRAPER_NAME: çˆ¬èŸ²åç¨±ï¼ˆå°æ‡‰ scrapers/src/{name}/scraper.tsï¼‰
#   SOURCE_URL: å•†å“é é¢ URL
#   OUTPUT_DIR: JSONL è¼¸å‡ºç›®éŒ„
#   OPTIONS: å¯é¸åƒæ•¸
#     --locale LOCALE        èªç³»ï¼ˆé è¨­ en-USï¼‰
#     --max-reviews N        æœ€å¤šæŠ“å–è©•è«–æ•¸ï¼ˆé è¨­ 500ï¼‰
#     --batch-size N         æ¯è¡Œ JSONL æœ€å¤šè©•è«–æ•¸ï¼ˆé è¨­ 50ï¼‰
#     --headless BOOL        æ˜¯å¦ä½¿ç”¨ headless æ¨¡å¼ï¼ˆé è¨­ trueï¼‰
#     --timeout MS           è¶…æ™‚æ¯«ç§’æ•¸ï¼ˆé è¨­ 30000ï¼‰
#
# å›å‚³å€¼ï¼š
#   0  = æˆåŠŸ
#   >0 = å¤±æ•—
########################################
playwright_scrape() {
  local scraper_name="$1"
  local source_url="$2"
  local output_dir="$3"
  shift 3

  # è§£æå¯é¸åƒæ•¸
  local locale="${PLAYWRIGHT_LOCALE:-en-US}"
  local max_reviews="${PLAYWRIGHT_MAX_REVIEWS:-500}"
  local batch_size="${PLAYWRIGHT_BATCH_SIZE:-50}"
  local headless="${PLAYWRIGHT_HEADLESS:-true}"
  local timeout="${PLAYWRIGHT_TIMEOUT:-30000}"

  while [[ $# -gt 0 ]]; do
    case "$1" in
      --locale)     locale="$2"; shift 2 ;;
      --max-reviews) max_reviews="$2"; shift 2 ;;
      --batch-size) batch_size="$2"; shift 2 ;;
      --headless)   headless="$2"; shift 2 ;;
      --timeout)    timeout="$2"; shift 2 ;;
      *) echo "âš ï¸  [playwright_scrape] æœªçŸ¥åƒæ•¸ï¼š$1" >&2; shift ;;
    esac
  done

  playwright_check_env || return 1

  local project_root
  project_root="$(cd "${_playwright_lib_dir}/.." && pwd)"
  local scraper_path="$project_root/scrapers/src/${scraper_name}/scraper.ts"

  if [[ ! -f "$scraper_path" ]]; then
    echo "âŒ [playwright_scrape] æ‰¾ä¸åˆ°çˆ¬èŸ²ï¼š$scraper_path" >&2
    return 1
  fi

  mkdir -p "$output_dir"

  echo "ğŸ•·ï¸  [playwright_scrape] åŸ·è¡Œçˆ¬èŸ²ï¼š$scraper_name" >&2
  echo "    URL: $source_url" >&2
  echo "    è¼¸å‡º: $output_dir" >&2
  echo "    èªç³»: $locale | æœ€å¤§è©•è«–: $max_reviews | æ‰¹æ¬¡å¤§å°: $batch_size" >&2

  local exit_code=0
  (
    cd "$project_root/scrapers" && \
    npx tsx "$scraper_path" \
      --url "$source_url" \
      --output "$output_dir" \
      --locale "$locale" \
      --max-reviews "$max_reviews" \
      --batch-size "$batch_size" \
      --headless "$headless" \
      --timeout "$timeout"
  ) || exit_code=$?

  if [[ $exit_code -ne 0 ]]; then
    echo "âŒ [playwright_scrape] çˆ¬èŸ²åŸ·è¡Œå¤±æ•— (exit=$exit_code)" >&2
    return 1
  fi

  echo "âœ… [playwright_scrape] å®Œæˆï¼š$scraper_name" >&2
  return 0
}

########################################
# playwright_scrape_urls --scraper NAME --input FILE --output DIR [OPTIONS...]
#
# åŠŸèƒ½ï¼š
#   - å¾ URL æ¸…å–®æª”æ¡ˆæ‰¹æ¬¡åŸ·è¡Œçˆ¬èŸ²
#
# åƒæ•¸ï¼š
#   --scraper NAME     çˆ¬èŸ²åç¨±
#   --input FILE       URL æ¸…å–®æª”æ¡ˆï¼ˆæ¯è¡Œä¸€å€‹ URLï¼Œ# é–‹é ­ç‚ºè¨»è§£ï¼‰
#   --output DIR       JSONL è¼¸å‡ºç›®éŒ„
#   --locale LOCALE    èªç³»ï¼ˆé è¨­ en-USï¼‰
#   --max-reviews N    æ¯å€‹å•†å“æœ€å¤šæŠ“å–è©•è«–æ•¸ï¼ˆé è¨­ 500ï¼‰
#   --batch-size N     æ¯è¡Œ JSONL æœ€å¤šè©•è«–æ•¸ï¼ˆé è¨­ 50ï¼‰
#
# å›å‚³å€¼ï¼š
#   0  = å…¨éƒ¨æˆåŠŸ
#   1  = éƒ¨åˆ†æˆ–å…¨éƒ¨å¤±æ•—
########################################
playwright_scrape_urls() {
  local scraper_name=""
  local input_file=""
  local output_dir=""
  local locale="en-US"
  local max_reviews=500
  local batch_size=50

  while [[ $# -gt 0 ]]; do
    case "$1" in
      --scraper)     scraper_name="$2"; shift 2 ;;
      --input)       input_file="$2"; shift 2 ;;
      --output)      output_dir="$2"; shift 2 ;;
      --locale)      locale="$2"; shift 2 ;;
      --max-reviews) max_reviews="$2"; shift 2 ;;
      --batch-size)  batch_size="$2"; shift 2 ;;
      *) echo "âš ï¸  [playwright_scrape_urls] æœªçŸ¥åƒæ•¸ï¼š$1" >&2; shift ;;
    esac
  done

  if [[ -z "$scraper_name" || -z "$input_file" || -z "$output_dir" ]]; then
    echo "âŒ [playwright_scrape_urls] ç¼ºå°‘å¿…è¦åƒæ•¸ï¼š--scraper, --input, --output" >&2
    return 1
  fi

  if [[ ! -f "$input_file" ]]; then
    echo "âŒ [playwright_scrape_urls] æ‰¾ä¸åˆ° URL æ¸…å–®ï¼š$input_file" >&2
    return 1
  fi

  local total=0 success=0 failed=0

  while IFS= read -r url || [[ -n "$url" ]]; do
    # è·³éç©ºè¡Œå’Œè¨»è§£
    [[ -z "$url" || "$url" == \#* ]] && continue

    # å»é™¤å‰å¾Œç©ºç™½
    url="$(echo "$url" | xargs)"
    [[ -z "$url" ]] && continue

    total=$((total + 1))

    if playwright_scrape "$scraper_name" "$url" "$output_dir" \
      --locale "$locale" \
      --max-reviews "$max_reviews" \
      --batch-size "$batch_size"; then
      success=$((success + 1))
    else
      failed=$((failed + 1))
      echo "âš ï¸  [playwright_scrape_urls] å¤±æ•—ï¼š$url" >&2
    fi
  done < "$input_file"

  # è¨˜éŒ„æœ€å¾Œæ“·å–æ™‚é–“
  date -u '+%Y-%m-%dT%H:%M:%SZ' > "$output_dir/.last_fetch"

  echo "ğŸ“Š [playwright_scrape_urls] çµæœï¼š$success/$total æˆåŠŸï¼Œ$failed å¤±æ•—" >&2

  if [[ $failed -gt 0 ]]; then
    return 1
  fi
  return 0
}
